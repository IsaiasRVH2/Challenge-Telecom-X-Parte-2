# ğŸ“Š Telecom X â€“ Parte 2: PredicciÃ³n de CancelaciÃ³n (Churn)

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Classification-green.svg)
![Status](https://img.shields.io/badge/Status-Completed-success.svg)


## ğŸ¯ MisiÃ³n

Desarrollar **modelos predictivos** capaces de prever quÃ© clientes tienen mayor probabilidad de cancelar sus servicios.

La empresa quiere anticiparse al problema de la cancelaciÃ³n, y es necesaro construir un pipeline robusto para esta etapa inicial de modelado.

## ğŸ§  Objetivos del DesafÃ­o

- âœ… Preparar los datos para el modelado (tratamiento, codificaciÃ³n, normalizaciÃ³n)
- âœ… Realizar anÃ¡lisis de correlaciÃ³n y selecciÃ³n de variables
- âœ… Entrenar dos o mÃ¡s modelos de clasificaciÃ³n
- âœ… Evaluar el rendimiento de los modelos con mÃ©tricas
- âœ… Interpretar los resultados, incluyendo la importancia de las variables
- âœ… Crear una conclusiÃ³n estratÃ©gica seÃ±alando los principales factores que influyen en la cancelaciÃ³n

## ğŸ“ Estructura del Proyecto

```
Challenge Telecom X - Parte 2/
â”‚
â”œâ”€â”€ datos/
â”‚   â””â”€â”€ datos_tratados.csv          # Dataset preprocesado
â”‚
â”œâ”€â”€ modelos/
â”‚   â”œâ”€â”€ champion.pkl                # Modelo final entrenado
â”‚   â””â”€â”€ onehotencoder.pkl           # Codificador para variables categÃ³ricas
â”‚
â”œâ”€â”€ telecomx_churn_prediction.ipynb # Notebook principal con anÃ¡lisis completo
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â””â”€â”€ README.md                       # Este archivo
```

## ğŸ”¬ MetodologÃ­a

### 1. PreparaciÃ³n de Datos

- **Carga y exploraciÃ³n** del dataset tratado
- **EliminaciÃ³n** de columnas no predictivas (`CustomerID`)
- **CodificaciÃ³n** de variables categÃ³ricas usando OneHotEncoder
- **Encoding** de la variable objetivo con LabelEncoder
- **Balanceo** de clases mediante tÃ©cnicas de sampling

### 2. AnÃ¡lisis del Desbalanceo

Se identificÃ³ que solo el **26.54%** de los clientes abandonaron el servicio, lo que representa un dataset desbalanceado. Se evaluaron dos estrategias:

- **NearMiss (Undersampling)**: Recall = 0.7560 âœ…
- **SMOTE (Oversampling)**: Recall = 0.7512

**DecisiÃ³n**: Se seleccionÃ³ **NearMiss** por su mejor desempeÃ±o en recall.

### 3. AnÃ¡lisis Exploratorio

Se realizaron anÃ¡lisis de correlaciÃ³n y visualizaciones para identificar patrones:

- **Heatmap de correlaciones** entre variables numÃ©ricas
- **Boxplots** de Churn vs Tenure, ChargesTotal y ChargesMonthly
- IdentificaciÃ³n de tendencias clave

### 4. Modelado y EvaluaciÃ³n

Se entrenaron y evaluaron **7 modelos** diferentes:

| Modelo | Recall | F1-Score | Accuracy | Precision |
|--------|--------|----------|----------|-----------|
| **Logistic Regression** | **0.756** | **0.713** | **0.675** | **0.675** |
| SVC | 0.751 | 0.710 | 0.673 | 0.673 |
| MLP | 0.727 | 0.694 | 0.664 | 0.664 |
| XGBoost | 0.665 | 0.674 | 0.684 | 0.684 |
| Random Forest | 0.630 | 0.656 | 0.683 | 0.683 |
| Decision Tree | 0.606 | 0.642 | 0.679 | 0.680 |
| Baseline | 0.500 | 0.333 | 0.500 | 0.250 |

**Modelo CampeÃ³n**: **RegresiÃ³n LogÃ­stica** con penalizaciÃ³n L1

### 5. SelecciÃ³n de CaracterÃ­sticas

Utilizando **regularizaciÃ³n L1**, se redujo el modelo a las **13 variables mÃ¡s importantes**, manteniendo el rendimiento:

- **Recall**: 74.8%
- **F1-Score**: 71.3%
- **Accuracy**: 67.5%

## ğŸ”‘ Factores Clave Identificados

### Factores que AUMENTAN el riesgo de churn:

1. **Cargos Totales Altos** (Coef: +3.59) - Factor mÃ¡s crÃ­tico
2. **Contratos Mes a Mes** (Coef: +0.71) - Alta volatilidad
3. **MÃ©todo de Pago: Cheque ElectrÃ³nico** (Coef: +0.43) - FricciÃ³n en pagos
4. **FacturaciÃ³n ElectrÃ³nica/Paperless** (Coef: +0.36) - Paradoja digital

### Factores que RETIENEN al cliente:

1. **AntigÃ¼edad/Tenure** (Coef: -3.96) - ProtecciÃ³n mÃ¡s fuerte
2. **Servicio TelefÃ³nico** (Coef: -0.70) - Ancla de lealtad
3. **Seguridad en LÃ­nea** (Coef: -0.46) - Valor agregado
4. **Soporte TÃ©cnico** (Coef: -0.41) - Servicio diferenciador

## ğŸ’¡ Estrategias de RetenciÃ³n Propuestas

### 1. ğŸ“ Programa de MigraciÃ³n de Contratos
DiseÃ±ar campaÃ±as de **upselling** dirigidas a usuarios con contrato "Mes a Mes". Ofrecer:
- Descuento mensual por contrato anual
- Servicios extra gratuitos

### 2. ğŸ“¦ Empaquetamiento EstratÃ©gico
Regalar **Soporte TÃ©cnico** y **Seguridad en LÃ­nea** durante los primeros 3-6 meses a nuevos usuarios para incrementar la percepciÃ³n de valor durante la etapa crÃ­tica de retenciÃ³n.

### 3. ğŸ’³ AuditorÃ­a de Experiencia de Pago
Investigar el flujo de pago con "Cheque ElectrÃ³nico" y promover la transiciÃ³n hacia mÃ©todos automÃ¡ticos mediante incentivos.

### 4. ğŸ¯ IntervenciÃ³n Temprana
Integrar el modelo al CRM para identificar clientes en riesgo y realizar seguimiento proactivo antes de que decidan cancelar.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.8+**
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - Operaciones numÃ©ricas
- **scikit-learn** - Modelado y preprocesamiento
- **imbalanced-learn** - TÃ©cnicas de balanceo
- **XGBoost** - Gradient boosting
- **matplotlib / seaborn** - VisualizaciÃ³n
- **pickle** - SerializaciÃ³n de modelos

## ğŸš€ CÃ³mo Usar Este Proyecto

### 1. Clonar el repositorio

```bash
git clone https://github.com/IsaiasRVH2/Challenge-Telecom-X-Parte-2.git
cd Challenge-Telecom-X-Parte-2
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Ejecutar el notebook

```bash
jupyter notebook telecomx_churn_prediction.ipynb
```

### 4. Cargar el modelo entrenado

```python
import pickle

# Cargar el codificador
with open('modelos/onehotencoder.pkl', 'rb') as file:
    encoder = pickle.load(file)

# Cargar el modelo
with open('modelos/champion.pkl', 'rb') as file:
    modelo = pickle.load(file)
```

## ğŸ“Š Resultados Principales

- âœ… **IdentificaciÃ³n exitosa del 74.8%** de clientes en riesgo de churn
- âœ… **Modelo interpretable** que permite entender por quÃ© se van los clientes
- âœ… **ReducciÃ³n a 13 variables clave** sin pÃ©rdida de rendimiento
- âœ… **Insights accionables** para el equipo de negocio

## ğŸ“ Aprendizajes Clave

1. **El desbalanceo importa**: TÃ©cnicas como NearMiss pueden superar significativamente al SMOTE en ciertos contextos
2. **La interpretabilidad es valiosa**: Modelos mÃ¡s simples (RegresiÃ³n LogÃ­stica) pueden ser superiores a modelos complejos cuando el negocio necesita entender el "por quÃ©"
3. **La regularizaciÃ³n L1 es poderosa**: Permite reducir dimensionalidad manteniendo rendimiento
4. **El recall es crÃ­tico en churn**: Es mÃ¡s costoso perder un cliente que no identificamos, que investigar un falso positivo

## ğŸ‘¤ Autor

**Isaias RVH2**
- GitHub: [@IsaiasRVH2](https://github.com/IsaiasRVH2)

## ğŸ“œ Licencia

Este proyecto es parte del programa **Oracle Next Education** y fue desarrollado con fines educativos.

---

â­ **Â¡Si este proyecto te resultÃ³ Ãºtil, considera darle una estrella!** â­